<![CDATA[<div align="center">

# ğŸ¤– Agentic RAG Knowledge Assistant

### Enterprise-Grade AI Research Assistant with Self-Correcting Retrieval

[![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![React](https://img.shields.io/badge/React-18+-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://react.dev)
[![LangGraph](https://img.shields.io/badge/LangGraph-0.2+-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white)](https://langchain-ai.github.io/langgraph/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-412991?style=for-the-badge&logo=openai&logoColor=white)](https://openai.com)
[![Pinecone](https://img.shields.io/badge/Pinecone-Vector_DB-000000?style=for-the-badge)](https://pinecone.io)
[![Neo4j](https://img.shields.io/badge/Neo4j-GraphRAG-008CC1?style=for-the-badge&logo=neo4j&logoColor=white)](https://neo4j.com)

<br/>

**A production-ready RAG system featuring Corrective RAG, GraphRAG, real-time observability, and an intelligent agent workflow that self-corrects when retrieval fails.**

[Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Quick Start](#-quick-start) â€¢ [Usage](#-usage) â€¢ [API](#-api-reference) â€¢ [Contributing](#-contributing)

<br/>

<img src="docs/demo.gif" alt="Demo" width="800"/>

</div>

---

## ğŸ¯ Why This Project?

Traditional RAG systems have critical limitations:
- âŒ **Hallucination** when context is insufficient
- âŒ **No self-correction** when retrieval fails
- âŒ **Single-hop retrieval** misses entity relationships
- âŒ **Black-box processing** with no visibility into agent decisions

This project solves all of these with a **state-of-the-art agentic architecture**:

| Problem | Solution |
|---------|----------|
| Hallucination | Confidence scoring + automatic decline when uncertain |
| Failed retrieval | Corrective RAG with query rewriting + web search fallback |
| Missing relationships | Neo4j GraphRAG for entity-aware context enrichment |
| Black-box AI | Real-time agent workflow visualization in UI |

---

## âœ¨ Features

### ğŸ§  Intelligent Agent Workflow
- **Intent Classification** â€” Routes queries to the optimal processing path
- **Semantic Retrieval** â€” Pinecone vector search with configurable similarity thresholds
- **Document Grading** â€” LLM-based relevance scoring of retrieved chunks
- **Query Rewriting** â€” Automatic query transformation when initial retrieval fails
- **Web Search Fallback** â€” DuckDuckGo integration when knowledge base lacks information
- **Grounded Synthesis** â€” Strict citation-based response generation

### ğŸ“Š GraphRAG Integration
- **Entity Extraction** â€” Automatic identification of people, organizations, concepts
- **Knowledge Graph** â€” Neo4j-powered relationship storage and traversal
- **Hybrid Retrieval** â€” Combines vector similarity with graph-based context enrichment

### ğŸ” LLMOps & Observability
- **Arize Phoenix Integration** â€” Full trace visibility for debugging and optimization
- **Real-time Step Events** â€” Stream agent decisions to frontend via SSE
- **Latency Tracking** â€” Per-node timing metrics for performance analysis

### ğŸ’» Modern Developer Experience
- **Multi-file Upload** â€” Drag & drop multiple PDFs, process in parallel
- **Live Agent Visualization** â€” Watch Router â†’ Retrieval â†’ Grader â†’ Synthesis in real-time
- **Collapsible Citations** â€” Source documents with similarity scores
- **Dark Mode UI** â€” Premium glassmorphism design with smooth animations

---

## ğŸ— Architecture

```mermaid
flowchart TB
    subgraph Frontend["Frontend (React + Vite)"]
        UI[Chat Interface]
        Upload[Document Upload]
        Steps[Agent Steps Visualization]
    end

    subgraph Backend["Backend (FastAPI + LangGraph)"]
        API["/chat/stream SSE Endpoint"]
        
        subgraph Agent["LangGraph Agent Workflow"]
            Router[ğŸ¯ Router Node]
            Retrieval[ğŸ“š Retrieval Node]
            GraphRetrieval[ğŸ”— Graph Retrieval]
            Grader[âœ… Grader Node]
            Rewriter[âœï¸ Query Rewriter]
            WebSearch[ğŸŒ Web Search]
            Synthesis[ğŸ’¬ Synthesis Node]
        end
    end

    subgraph Storage["Data Layer"]
        Pinecone[(Pinecone Vector DB)]
        Neo4j[(Neo4j Graph DB)]
        Files[ğŸ“ Document Storage]
    end

    subgraph Observability["Observability"]
        Phoenix[Arize Phoenix]
    end

    UI --> API
    Upload --> Files
    API --> Router
    Router -->|knowledge_search| Retrieval
    Router -->|greeting/calculation| Synthesis
    Retrieval --> Pinecone
    Retrieval --> GraphRetrieval
    GraphRetrieval --> Neo4j
    GraphRetrieval --> Grader
    Grader -->|relevant| Synthesis
    Grader -->|not_relevant| Rewriter
    Rewriter -->|retry| Retrieval
    Rewriter -->|max_iterations| WebSearch
    WebSearch --> Synthesis
    Synthesis --> UI
    Agent -.->|traces| Phoenix
```

### Corrective RAG Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CORRECTIVE RAG PATTERN                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   Query â”€â”€â–º Router â”€â”€â–º Retrieval â”€â”€â–º Grader â”€â”€â”¬â”€â”€â–º Synthesis    â”‚
â”‚                           â–²                    â”‚                 â”‚
â”‚                           â”‚                    â”‚                 â”‚
â”‚                       Rewriter â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                           â”‚         (if not relevant)           â”‚
â”‚                           â–¼                                      â”‚
â”‚                      Web Search (after max retries)              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 18+
- Docker (for Neo4j)
- OpenAI API Key
- Pinecone API Key

### 1. Clone & Setup

```bash
git clone https://github.com/yourusername/agentic-rag-assistant.git
cd agentic-rag-assistant
```

### 2. Configure Environment

```bash
cp .env.example .env
```

Edit `.env` with your API keys:

```env
# Required
OPENAI_API_KEY=sk-...
PINECONE_API_KEY=...
PINECONE_INDEX_NAME=rag-knowledge-base
PINECONE_ENVIRONMENT=us-east-1

# Optional (for GraphRAG)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password123
```

### 3. Start Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r ../requirements.txt

# Run the server
PYTHONPATH=. uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### 4. Start Frontend

```bash
cd frontend
npm install
npm run dev
```

### 5. (Optional) Start Neo4j

```bash
docker-compose up neo4j -d
```

### 6. Access the Application

| Service | URL |
|---------|-----|
| Frontend | http://localhost:5173 |
| Backend API | http://localhost:8000 |
| API Docs | http://localhost:8000/docs |
| Neo4j Browser | http://localhost:7474 |

---

## ğŸ“– Usage

### Uploading Documents

1. Navigate to the **Documents** tab
2. Click **"Choose Files to Upload"** (supports multiple files)
3. Select PDFs, TXT, MD, DOCX, CSV, or JSON files
4. Click **"Ingest All Documents"** to process into vector store

Supported formats:
- ğŸ“„ PDF (research papers, reports)
- ğŸ“ TXT, MD (plain text, markdown)
- ğŸ“Š CSV, JSON (structured data)
- ğŸ“ƒ DOCX (Word documents)

### Asking Questions

Switch to the **Chat** tab and ask questions about your documents:

```
"Summarize the key findings from the uploaded research papers"
"What methodology was used in the machine learning study?"
"Compare the approaches discussed in the AI papers"
```

### Agent Workflow Visualization

Watch the agent's decision-making process in real-time:

| Step | Description |
|------|-------------|
| ğŸ¯ **Router** | Classifies intent (knowledge_search, calculation, greeting) |
| ğŸ“š **Retrieval** | Searches Pinecone for relevant document chunks |
| ğŸ”— **Graph Retrieval** | Enriches context with Neo4j entity relationships |
| âœ… **Grader** | Evaluates if retrieved documents answer the question |
| âœï¸ **Rewriter** | Transforms query if documents weren't relevant |
| ğŸŒ **Web Search** | Falls back to DuckDuckGo if KB lacks information |
| ğŸ’¬ **Synthesis** | Generates grounded response with citations |

---

## ğŸ“¡ API Reference

### Chat Endpoint (SSE Stream)

```http
POST /chat/stream
Content-Type: application/json

{
  "query": "What are the main findings?",
  "session_id": "optional-session-id"
}
```

**Response**: Server-Sent Events stream with:
- `step` events (agent workflow progress)
- `token` events (streaming response)
- `citation` events (source documents)
- `done` event (completion signal)

### Document Management

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/upload/` | POST | Upload a document |
| `/api/upload/documents` | GET | List all documents |
| `/api/upload/documents/{filename}` | DELETE | Delete a document |
| `/api/upload/ingest` | POST | Process documents into vector store |

### Health Check

```http
GET /health
```

---

## âš™ï¸ Configuration

### Backend Settings (`core/config.py`)

| Setting | Default | Description |
|---------|---------|-------------|
| `OPENAI_MODEL` | `gpt-4o-mini` | LLM for routing/synthesis |
| `OPENAI_EMBEDDING_MODEL` | `text-embedding-3-small` | Embedding model |
| `SIMILARITY_THRESHOLD` | `0.5` | Minimum similarity for retrieval |
| `RETRIEVAL_K` | `5` | Number of chunks to retrieve |
| `CHUNK_SIZE` | `1500` | Document chunk size |
| `CHUNK_OVERLAP` | `300` | Overlap between chunks |
| `MAX_ITERATIONS` | `3` | Max Corrective RAG retries |

### Frontend Environment

```env
VITE_API_URL=http://localhost:8000
```

---

## ğŸ§ª Testing

### Run Backend Tests

```bash
cd backend
pytest tests/ -v
```

### Test RAG Pipeline

```bash
# Ingest sample documents
python scripts/ingest.py

# Test query
curl -X POST http://localhost:8000/chat/stream \
  -H "Content-Type: application/json" \
  -d '{"query": "Summarize the documents"}'
```

---

## ğŸ“ Project Structure

```
agentic-rag-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ graph.py           # LangGraph workflow definition
â”‚   â”‚   â”œâ”€â”€ nodes.py           # Router, Retrieval, Synthesis nodes
â”‚   â”‚   â”œâ”€â”€ grader_node.py     # Document relevance grading
â”‚   â”‚   â”œâ”€â”€ web_search_node.py # DuckDuckGo fallback
â”‚   â”‚   â”œâ”€â”€ graph_retrieval_node.py # Neo4j hybrid retrieval
â”‚   â”‚   â””â”€â”€ state.py           # AgentState TypedDict
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ upload.py          # Document upload endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py          # Settings management
â”‚   â”‚   â”œâ”€â”€ graph_store.py     # Neo4j connection manager
â”‚   â”‚   â””â”€â”€ tracing.py         # Arize Phoenix instrumentation
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ ingest.py          # Document ingestion pipeline
â”‚   â””â”€â”€ main.py                # FastAPI application
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx  # Main chat UI
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentSteps.tsx     # Workflow visualization
â”‚   â”‚   â”‚   â””â”€â”€ DocumentUpload.tsx # File management
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                   # Uploaded documents
â”œâ”€â”€ docker-compose.yml         # Neo4j service
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md
```

---

## ğŸ›  Tech Stack

| Layer | Technology |
|-------|------------|
| **LLM Framework** | LangChain + LangGraph |
| **Vector Database** | Pinecone |
| **Graph Database** | Neo4j |
| **Backend** | FastAPI + Python 3.9+ |
| **Frontend** | React 18 + TypeScript + Vite |
| **Embeddings** | OpenAI text-embedding-3-small |
| **LLM** | OpenAI GPT-4o-mini |
| **Observability** | Arize Phoenix |
| **Web Search** | DuckDuckGo |

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [LangChain](https://langchain.com) & [LangGraph](https://langchain-ai.github.io/langgraph/) for the agent framework
- [Pinecone](https://pinecone.io) for vector search
- [Neo4j](https://neo4j.com) for graph database
- [Arize Phoenix](https://phoenix.arize.com) for observability
- [OpenAI](https://openai.com) for LLM and embeddings

---

<div align="center">

**Built with â¤ï¸ for the AI community**

â­ Star this repo if you found it helpful!

</div>
]]>
